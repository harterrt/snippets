# Done

* Consulting
  * Search 
    * [Bug 1336613](http://bugzil.la/1336613): Build pipeline for cliqz testpilot result data
      * Updating the search dataset schema from client feedback
      * Writing the `profile_daily` job https://github.com/harterrt/cliqz_ping_pipeline/blob/master/prof_daily_prototype.py
      * Ran into some problems backfilling the dataset. Before 2017-01-27 there
        is a sudden increase in testpilottest pings, which was clogging the job.
        One day of data was taking >5h on a big cluster. Refactored job and got
        this down to ~20m/day.
    * [Bug 1340318](http://bugzil.la/1340318): Cliqz testpilot data: has_addon field should be a boolean, not a varchar
      * Fixing this exposed a bug in parquet reader. The reader cannot open
        empty files of type boolean. Took some debugging but fixed the problem.
  * Security
    * [Bug 1339200](http://bugzil.la/1339200): Make containers data available in re:dash
      * Got test job up and running. Goal is to have this running by EOD.
        See the job here: https://github.com/harterrt/cliqz_ping_pipeline/blob/master/containers.py
    * Introducing myself to EKR
* Other
  * Wrote up [Linux User Counts are Easy to Overestimate](http://reports.telemetry.mozilla.org/post/projects/os_churn_md.kp)
* Review
  * [Daily Search Aggregates](https://github.com/mozilla/mozilla-reports/pull/23#event-963268736) - Significant amount of consulting
  * [CrashSummaryView Docs](https://github.com/mozilla/telemetry-batch-view/pull/173#event-950189519)

# Next

* Get documentation bugs filed
* Finalize the container tab ETL
* Refactor the ETL notebook so:
  * ipynb downloads a repo and fires off a `__main__()` function
  * it's easy to fork the repo and define a declarative ETL job
* Write-up the spark parquet writing bug identified during the cliqz backfill

# Blocking

Short week
