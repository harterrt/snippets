Done:
* Cross Sectional Dataset (xsec ds)
  * Review required aggregations from bcolloran
  * Prototype conversion to cross sectional format
    * Read data from local parquet shard
    * Convert dataframe to Dataset
        * Review best options for conversion (case class or schema?)
        * Implement sample conversion
    * Add tests for xsec conversion
  * Discuss requirements with bcolloran and rweiss
  * Add documentation on sampling l10l data locally
  * Incorporate code into batch view
    * Move from SparkContext to SQLContext
    * Full conversion unit test
  * Sample run over full data on cluster
    * Replace direct parquet read with HiveContext load
    * Start runs with spark-submit, not sbt
    * Implement logging to debug communication error
* Attend FX Data Progam meeting
* Trainings all week

Next:
* Cross Sectional Dataset:
  * debug [this error](https://github.com/harterrt/telemetry-batch-view/blob/xsec_ds/err.txt) when running on cluster
  * Save dataset to S3
  * Refactor to make fields more extensible
  * Fix up testing, make it less fragile
  * Send for initial review
* Write up progress so far in a series of blog posts:
  * Windows 10 case study
  * XSec dataset motivations and methods
  * Writing great documentation
